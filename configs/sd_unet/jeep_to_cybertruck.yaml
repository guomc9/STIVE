pretrained_sd_model_path: "./checkpoints/stable-diffusion-v1-4"
pretrained_concepts_model_path: "./checkpoints/sd_concepts/cybertruck"
output_dir: ".log/sd_unet/cybertruck/base/"
checkpoints_dir: "checkpoints/sd_unet/cybertruck"

train_data:
  video_paths:
    - "data/targets/car-turn/videos/car-turn.mp4"
    - "data/concepts/cybertruck/videos/cybertruck.mp4"
  prompts:
    - "a jeep driving down a curvy road in the countryside"
    - "a $CYBERTRUCK is driving through the forest"
  mask_paths:
    - "data/targets/car-turn/masks/car-turn_jeep_frame_masks.mp4"
    - "data/concepts/cybertruck/masks/cybertruck_car_frame_masks.mp4"
  num_frames: 6
  sample_stride: 6
  width: 512
  height: 512
  rand_slice: False
  target_video_paths:
    - "data/targets/car-turn/videos/car-turn.mp4"
  target_mask_paths:
    - "data/targets/car-turn/masks/car-turn_jeep_frame_masks.mp4"
  target_prompts:
    - "a $CYBERTRUCK driving down a curvy road in the countryside"

validation_data:
  source: "data/targets/car-turn/videos/car-turn.mp4"
  source_prompt: "a jeep driving down a curvy road in the countryside"
  edit_prompts:
    - "a $CYBERTRUCK driving down a curvy road in the countryside"
  num_frames: 6
  sample_stride: 6
  width: 512
  height: 512
  replace_indices: [[2]]    # jeep -> '$CYBERTRUCK'

lora_conf:
  r: 6
  lora_alpha: 1.0
  lora_dropout: 0.1
  target_modules:
    # - "^.*\\.attentions\\..*\\.attn1\\.to_q\\..*$"
    # - "^.*\\.attentions\\..*\\.attn2\\.to_q\\..*$"
    # - "^.*\\.attentions\\..*\\.ff\\.net\\.2\\..*$"
  bias: "none"

extra_trainable_modules:
  - "^.*\\.attentions\\..*\\.attn1\\.to_q\\..*$"
  - "^.*\\.attentions\\..*\\.attn2\\.to_q\\..*$"
  - "^.*\\.temp_lora_conv\\..*"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_q\\..*$"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_k\\..*$"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_v\\..*$"
  - "^.*\\.attentions\\..*\\.attn_temp\\..*$"

inference_conf:
  num_inference_steps: 30
  guidance_scale: 12.5
  use_inv_latent: True
  num_inv_steps: 30

# CHECK
sub_sot: True
cam_loss_type: 'mae'
enable_scam_loss: True
scam_weight: 0.0
scam_only_neg: True
enable_tcam_loss: True
tcam_only_neg: True
tcam_weight: 0.0
cam_loss_reduction: 'mean'
attn_check_steps: 15

learning_rate: 1.0e-5
batch_size: 1
num_train_epoch: 150
checkpointing_steps: 2000
validation_steps: 10

seed: 33
mixed_precision: 'fp16'
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True
enable_torch_2_attn: True
gradient_accumulation_steps: 1
