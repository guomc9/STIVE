pretrained_sd_model_path: "./checkpoints/stable-diffusion-v1-4"
pretrained_concepts_model_path: "./checkpoints/sd_concepts/pokeflag"
output_dir: ".log/sd_unet/pokeflag/base/"
checkpoints_dir: "checkpoints/sd_unet/pokeflag"

train_data:
  video_paths:
    - "data/targets/usa-flag/videos/usa-flag.mp4"
    - "data/concepts/pokeflag/videos/pokeflag.mp4"
  prompts:
    - "a flag waving in the wind"
    - "a $POKEFLAG waving in the wind"
  mask_paths:
    - "data/targets/usa-flag/masks/usa-flag_flag_frame_masks.mp4"
    - "data/concepts/pokeflag/masks/pokeflag_flag_frame_masks.mp4"
  num_frames: 6
  sample_stride: 6
  width: 512
  height: 512
  rand_slice: False
  target_video_paths:
    - "data/targets/usa-flag/videos/usa-flag.mp4"
  target_mask_paths:
    - "data/targets/usa-flag/masks/usa-flag_flag_frame_masks.mp4"
  target_prompts:
    - "a $POKEFLAG waving in the wind"

validation_data:
  source: "data/targets/usa-flag/videos/usa-flag.mp4"
  source_prompt: "a flag waving in the wind"
  edit_prompts:
    - "a $POKEFLAG waving in the wind"
  num_frames: 6
  sample_stride: 6
  width: 512
  height: 512
  replace_indices: [[2]]    # flag -> '$POKEFLAG'

lora_conf:
  r: 6
  lora_alpha: 1.0
  lora_dropout: 0.1
  target_modules:
    # - "^.*\\.attentions\\..*\\.attn1\\.to_q\\..*$"
    # - "^.*\\.attentions\\..*\\.attn2\\.to_q\\..*$"
    # - "^.*\\.attentions\\..*\\.ff\\.net\\.2\\..*$"
    # - "^.*\\.resnets\\..*\\.conv1\\.spatial_conv\\..*$"
  bias: "none"

extra_trainable_modules:
  - "^.*\\.attentions\\..*\\.attn1\\.to_q\\..*$"
  - "^.*\\.attentions\\..*\\.attn2\\.to_q\\..*$"
  - "^.*\\.temp_lora_conv\\..*"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_q\\..*$"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_k\\..*$"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_v\\..*$"
  - "^.*\\.attentions\\..*\\.attn_temp\\..*$"

inference_conf:
  num_inference_steps: 30
  guidance_scale: 12.5
  use_inv_latent: True
  num_inv_steps: 30

# CHECK
sub_sot: True
cam_loss_type: 'mae'
unet_begin_store_idx: 0
enable_scam_loss: True
scam_weight: 0.1
scam_only_neg: True
enable_tcam_loss: True
tcam_only_neg: True
tcam_weight: 0.1
cam_loss_reduction: 'mean'
attn_check_steps: 15

learning_rate: 1.0e-5
batch_size: 1
num_train_epoch: 150
checkpointing_steps: 2000
validation_steps: 10

seed: 33
mixed_precision: 'fp16'
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True
enable_torch_2_attn: True
gradient_accumulation_steps: 1
