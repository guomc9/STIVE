pretrained_sd_model_path: "./checkpoints/stable-diffusion-v1-4"
pretrained_concepts_model_path: "./checkpoints/sd_concepts/star"
output_dir: ".log/sd_unet/star/base/"
checkpoints_dir: "checkpoints/sd_unet/star"

train_data:
  video_paths:
    - "data/targets/capsule-rot/videos/capsule-rot.mp4"
    - "data/concepts/star/videos/star.mp4"
  prompts:
    - "several capsule moving on the track"
    - "a $STAR"
  mask_paths:
    - "data/targets/capsule-rot/masks/capsule-rot_capsule_frame_masks.mp4"
    - "data/concepts/star/masks/star_star_frame_masks.mp4"
  num_frames: 6
  sample_stride: 6
  width: 512
  height: 512
  rand_slice: False
  target_video_paths:
    - "data/targets/capsule-rot/videos/capsule-rot.mp4"
  target_mask_paths:
    - "data/targets/capsule-rot/masks/capsule-rot_capsule_frame_masks.mp4"
  target_prompts:
    - "several $STAR moving on the track"

validation_data:
  source: "data/targets/capsule-rot/videos/capsule-rot.mp4"
  source_prompt: "several capsule moving on the track"
  edit_prompts:
    - "several $STAR moving on the track"
  num_frames: 6
  sample_stride: 6
  width: 512
  height: 512
  replace_indices: [[2]]    # capsule -> '$STAR'

lora_conf:
  r: 6
  lora_alpha: 1.0
  lora_dropout: 0.1
  target_modules:
    # - "^.*\\.attentions\\..*\\.attn1\\.to_q\\..*$"
    # - "^.*\\.attentions\\..*\\.attn2\\.to_q\\..*$"
    # - "^.*\\.attentions\\..*\\.ff\\.net\\.2\\..*$"
  bias: "none"

extra_trainable_modules:
  - "^.*\\.attentions\\..*\\.attn1\\.to_q\\..*$"
  - "^.*\\.attentions\\..*\\.attn2\\.to_q\\..*$"
  - "^.*\\.temp_lora_conv\\..*"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_q\\..*$"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_k\\..*$"
  # - "^.*\\.attentions\\..*\\.attn_temp\\.to_v\\..*$"
  - "^.*\\.attentions\\..*\\.attn_temp\\..*$"

inference_conf:
  num_inference_steps: 30
  guidance_scale: 12.5
  use_inv_latent: True
  num_inv_steps: 30

# CHECK
sub_sot: True
cam_loss_type: 'mae'
unet_begin_store_idx: 0
enable_scam_loss: True
scam_weight: 0.1
scam_only_neg: True
enable_tcam_loss: True
tcam_only_neg: True
tcam_weight: 0.1
cam_loss_reduction: 'mean'
attn_check_steps: 15

learning_rate: 5.0e-6
batch_size: 1
num_train_epoch: 200
checkpointing_steps: 2000
validation_steps: 10

seed: 33
mixed_precision: 'fp16'
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True
enable_torch_2_attn: True
gradient_accumulation_steps: 1
